{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#please make sure you have the following libraries installed before continuing running this notebook\n",
    "#pip install tensorflow\n",
    "#keras needs tensorflow or other backends as caffe or theano\n",
    "#pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Glove text word vector file here: https://www.dropbox.com/s/my83b23ev2h9qgp/glove.6B.50d.txt?dl=1\n",
    "After downloading please place it in the directory same as that of this notebook or give appropriate path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framing Sentiment analysis as a deep Learning Problem\n",
    "1) Training a word vector generation model (such as Word2Vec) or loading pretrained word vectors\n",
    "2) Creating an ID's matrix for our training set (We'll discuss this a bit later)\n",
    "3) RNN (With LSTM units) graph creation\n",
    "4) Training \n",
    "5) Testing\n",
    "\n",
    "\n",
    "Also, we use Glove vector generation model for word2vec embeddings here.\n",
    "We're going to be importing two different data structures, one will be a Python list with the 400,000 words, and one will be a 400,000 x 50 dimensional embedding matrix that holds all of the word vector values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp = pd.read_csv('https://raw.githubusercontent.com/shrikumarp/shrikumarpp1/master/yelp.csv', usecols = [\"stars\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAEZCAYAAAAOi/YKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm4XWV99vHvbZgHTYAAMQNBCQrY\nihgBxRcZFAGtYC0VrEwCUV94lcHK8FqZirVW0Xpp1SApAZSACCVFKqQMpUEZAoVAiEgYc0iAQJhF\nhnD3j/Uc2RzOOVknnL13ztn357rWddb+rWet57d3Lti//axnrSXbREREROd5U7sTiIiIiPZIERAR\nEdGhUgRERER0qBQBERERHSpFQERERIdKERAREdGhUgRErAQkbSZpWFyvK+kISY9KelbSWwbheF2S\ndhqE1BqPuZOkeYN5zIihKEVAxCCR9DNJ03rEPiTpcUljmtivJH1N0v3li7dL0s8ats+WdFCz+u+R\nyxrAt4Gdba9j+6lW9DtQtq+xvVW784hotxQBEYPnS8Cekj4Cf/pCPAM4xvbiJvb7OWBfYBfb6wDv\nA64ZrINLWmUAzTcGVrc94F/Zkt4kKf9Pimih/AcXMUhsPw78P2CqpLWBE4F7bJ8Ff/qSO0HSPZIe\nkzRD0qjejlV+vZ8maY6kpyRd3Fdbqi/9X9u+t+Sx2PYZ5Tj/CLwf+HEZJfheif+gjBg8LekmSR9o\n6PvvJZ0v6TxJzwCflbS9pFtK+0ck/VMvOW8BzCvrz0q6oqx/sOF93Chpux7v81RJvwWeAyb08R63\nkzRf0hOSzpS0etn/UEnXNBxvFUmWNLG8/njZ75nyfo8q8Q9Lur9hvy5JR0u6veR5XncfZfsnJN0m\n6cmS87satp0gaVH5bH7XfeqizmcW0Xa2s2TJMogLcCEwE3gcmNAQ/wpwHTAWWAM4EzinbNus+s/x\nT21nAwuBLYG1gX8Dzuqjv4NKX18B3guM6LF9NnBQj9j+wHrAKsCxwENUv+AB/h54EfgLqh8KawI3\nAfuV7esC2/WRS8/3sQHwFLBf6euzJddRDbndD2wBrAqs0ssxu4C5wLhyvOuBk8q2Q4FrGtquAhiY\nWF4vAT5Q1tcDtinrHwbu79HH9VQjGesDvwcOLdveBzxS/o6gGnm5B1gN2Ap4ANi4tN0UeFtZr/WZ\nZcnSziUjARGD73BgF+AU2w82xD8PnGD7Idt/BE4C/rqfIfDptu+0/RzwdWBfSerZyNVIw5HAHsC1\nwKOSvtJfgrbPsb3U9svAt4A3U32Bd5tt+99tv2L7eeAlYJKk9W0/Y/uG5X4Klb8A5tk+z/bLts8F\n7gU+1tBmmu35tl8q+fTm+7a7bD8GfIOqqKjjJWBLSeuW93tLP22/Z/thVyM6lwJbl/gU4F9s32R7\nme3ueR/vA16mKui2krSK7ftcRmRY8c8somVSBEQMMtuPAI9RhsYbTAD+vQwpPwncTvWrdcM+DrWw\nYf0BYHWqX7O99XmO7V2BkVRFyD9I2rWvHCV9tQxdPwU8QTXasEEffQMcTDUqcVcZ0t+zr2P38NaS\ne6MHqEZD+uqrNz0/i7fW7P+TwCeAByVd03gqohcPN6z/AVinrG8CHNv971b+7cYAY23fBRwDnEJV\nfJ0naeOy34p+ZhEtkyIgonW6gI/YHtmwrGH74T7aj29YnwC8ACztr4Pya3oGVQHSfd76NZceStoZ\nOBr4FFXRMAp4FmgcZXjNPrbvsr0vVcHyHeCXZeLj8iyi+hJtNIHq9EOvffWh52exqKw/B6zVsG3j\nhnVs32D7EyXvS4EZNfrqaSFwco9/t7VsX1D6ONf2DlSnAkYA/1DiK/qZRbRMioCI1vkx8A1JEwAk\nbSjpE/20P0DSO8skw5OBC2y/7gtT0uck7Slp3TL58GPAO4AbS5NHgLc17LIu1TD2Y1Tn4U+iGgno\nk6T9JW1g+xWqc/wGXln+W+ZSqqHyT5dJe5+hOu1wWY19Gx0haayk9YHjgfNL/DbgzyX9maQ1qSZj\ndue8pqTPSHqz7ZeAZ4BlA+wXYCpwuKT3qbKOpL+QtLakLSTtXCYRPl+WZaX/Ff3MIlomRUBE65wO\n/Bq4ssy6/w3VeeW+nAOcCyym+oV5ZB/tnga+RvWL9Qmqc+ZTbP+2bP8esF8Zyj6d6gv4P4G7qSbl\nPV366M+ewPyS97eBT9t+cTn7YHsJ1XD8sVQTAo8CPm673xGNXpxXcr4HuIvqPWL7zrJ+TYlf22O/\nA4EHJD0NHEI1IXJAyrn8LwI/ovp8f081wRGqUzTfoiqoHqYaVfla2bZCn1lEK6mXHxYR0WaSZgM/\nLZP+IiKaIiMBERERHSpFQERERIfK6YCIiIgOlZGAiIiIDjWQB4MMSRtssIEnTpzY7jQiIiJa5uab\nb37M9ujltRv2RcDEiROZM2dOu9OIiIhoGUk979TZq5wOiIiI6FApAiIiIjpUioCIiIgOlSIgIiKi\nQ6UIiIiI6FApAiIiIjpUioCIiIgO1ZIiQNIakm6UdJukeZJOLvGzJN0n6daybF3ikvR9SQskzZW0\nTcOxDpR0d1kObEX+ERERw1Grbhb0ArCL7WclrQrMlvQfZdvf2r6wR/s9gEll2Y7qOd7bSVoPOBGY\nDBi4WdJM20+05F1EREQMIy0pAlw9pejZ8nLVsvT35KK9gLPLftdLGilpDLATMMv2UgBJs4DdgfPe\nSH6f/edfvZHdh71zv/yxdqcQERFN0LI5AZJGSLoVeJTqi/yGsum0MuT/XUmrl9hYYGHD7l0l1le8\nZ19TJM2RNGfJkiWD/l4iIiKGg5YVAbaX2d4aGAdsK+ldwPHAO4H3AesBx5bm6u0Q/cR79jXV9mTb\nk0ePXu7zEyIiIjpSy68OsP0kcA2wu+3FrrwA/CuwbWnWBYxv2G0csKifeERERAxQq64OGC1pZFlf\nE/gw8Ltynh9JAvYG7ii7zAQOKFcJbA88ZXsxcDmwm6RRkkYBu5VYREREDFCrrg4YA0yXNIKq8LjA\n9qWSrpI0mmqY/1bgC6X9ZcCewALgD8DBALaXSjoVuKm0O6V7kmBEREQMTKuuDpgLvKeX+C59tDdw\neB/bpgHTBjXBiIiIDpQ7BkZERHSoFAEREREdKkVAREREh0oREBER0aFadXVABA+f8el2p7DS2viw\n89udQkR0oIwEREREdKgUARERER0qRUBERESHShEQERHRoVIEREREdKgUARERER0qRUBERESHShEQ\nERHRoVIEREREdKgUARERER0qRUBERESHShEQERHRoVIEREREdKgUARERER0qRUBERESHakkRIGkN\nSTdKuk3SPEknl/imkm6QdLek8yWtVuKrl9cLyvaJDcc6vsTvkvTRVuQfERExHLVqJOAFYBfb7wa2\nBnaXtD3wj8B3bU8CngAOKe0PAZ6wvRnw3dIOSVsC+wJbAbsD/yJpRIveQ0RExLDSkiLAlWfLy1XL\nYmAX4MISnw7sXdb3Kq8p23eVpBKfYfsF2/cBC4BtW/AWIiIihp2WzQmQNELSrcCjwCzgHuBJ2y+X\nJl3A2LI+FlgIULY/BazfGO9ln4iIiBiAlhUBtpfZ3hoYR/XrfYvempW/6mNbX/HXkDRF0hxJc5Ys\nWbKiKUdERAxrLb86wPaTwDXA9sBISauUTeOARWW9CxgPULa/BVjaGO9ln8Y+ptqebHvy6NGjm/E2\nIiIihrwVKgIk7SxpxwG0Hy1pZFlfE/gwMB+4Gvir0uxA4JKyPrO8pmy/yrZLfN9y9cCmwCTgxhV5\nDxEREZ2uVhEg6b8k7VDWjwVmAOdJOqFmP2OAqyXNBW4CZtm+FDgWOFrSAqpz/meW9mcC65f40cBx\nALbnARcAdwK/Bg63vaxmDhEREdFgleU3AeBdwPVl/TBgJ+BZ4DrgG8vb2fZc4D29xO+ll9n9tv8I\n7NPHsU4DTquZd0RERPShbhHwJsCS3g7I9nwASaOalllEREQ0Vd0iYDbwA6ph/YsBSkHwWJPyioiI\niCarOzHwIOBJYC5wUom9E/jnwU8pIiIiWqHWSIDtx4ETesR+1ZSMIiIioiXqXh2wuqTTJN0r6akS\n203SEc1NLyIiIpql7umA71JdIfA3vHqHvnnAF5uRVERERDRf3YmBnwQ2s/2cpFcAbD8kKfftj4iI\nGKLqjgS8SI+CQdJo4PFBzygiIiJaom4R8AtgerlVL5LGUF0yOKNZiUVERERz1S0CTgDuB24HRgJ3\nUz245+TmpBURERHNVvcSwReBI4Ejy2mAx8oDfSIiImKIqnuJ4JaSNiovnwdOkvR1SWs1L7WIiIho\nprqnA35OdRoA4NvAjsD7gZ80I6mIiIhovrqXCE60fZckUV0uuBXViMB9TcssIiIimqpuEfCCpHWB\nLYGFth+TtAqwRvNSi4iIiGaqWwT8HLgKWJfq0kCAbchIQERExJBV9+qAoyTtBrxk++oSfgU4qmmZ\nRURERFPVHQnA9hXd65LeBiyxPacpWUVERETT1b1E8DxJHyjrB1M9POhOSYc0M7mIiIhonrqXCO4K\ndP/qPxr4MLAtcFwzkoqIiIjmq3s6YDXbL5anBq5n+zqAhhsIRURExBBTdyTgVknHA38H/AqgFARP\n19lZ0nhJV0uaL2mepC+X+EmSHpJ0a1n2bNjneEkLJN0l6aMN8d1LbIGkjERERESsoLojAYcApwIv\nAX9bYu8HflZz/5eBY2zfUu43cLOkWWXbd21/u7GxpC2BfaluSvRW4D8lbV42/xD4CNAF3CRppu07\na+YRERERRd1LBO8BPtMjdiFwYc39FwOLy/ozkuYDY/vZZS9ghu0XgPskLaCagwCwwPa9AJJmlLYp\nAiIiIgao7tUBknSYpCslzS2xHSX99UA7lDQReA9wQwkdIWmupGmSRpXYWGBhw25dJdZXvGcfUyTN\nkTRnyZIlA00xIiKiI9SdE3AK1SmBM4AJJdYFHDuQziStA/wSONL208CPgLcDW1ONFHynu2kvu7uf\n+GsD9lTbk21PHj169EBSjIiI6Bh15wQcBLynPDPgRyV2H/C2uh1JWpWqAPiZ7YsAbD/SsP0M4NLy\nsgsY37D7OGBRWe8rHhEREQNQdyRgBPBsWe/+5b1OQ6xf5emDZwLzbZ/eEB/T0OyTwB1lfSawr6TV\nJW0KTAJuBG4CJknaVNJqVJMHZ9Z8DxEREdGg7kjAZcDpko6CP32pnwr8e839dwD2B26XdGuJnQDs\nJ2lrqsLifuDzALbnSbqAasLfy8DhtpeVvo8ALqcqTKbZnlczh4iIiGhQtwg4GjgbeApYlWoE4Arg\ngDo7255N7+fzL+tnn9OA03qJX9bffhEREVFP3UsEnwb2lrQhsAmw0PbDTc0sIiIimqrunIBGjwNr\nSXpbeZpgREREDEG1RgIk7U41sW9Mj02mOjcfERERQ0zdkYAfUk0EXNv2mxqWFAARERFDVN2JgaOA\nn9h+3Y15IiIiYmiqOxJwJnBwMxOJiIiI1qo7ErA98KXy6N7XXBVge8dBzyoiIiKarm4R8NOyRERE\nxDBR9z4B05udSERERLRWn0WApP1tn1PWP9dXO9vTmpFYRERENFd/IwH7AeeU9f37aGMgRUBERMQQ\n1GcRYHvPhvWdW5NOREREtEqtSwQljZa0TlkfIelgSftLWpHbDkdERMRKoO6X+KXApLL+DeArwDHA\nd5qRVERERDRf3UsENwduLet/A3yA6nHC84CjmpBXRERENFndImAZsJqkzYGnbD9YTgWs07zUIiIi\nopnqFgH/AVwArA/MKLEtgYeakVREREQ0X90i4FDgQOAlXr1scAPgpCbkFBERES1Q946BLwBTe8Su\naUZCERER0Rq1igBJ51DdGOh1bB8wqBlFRERES9S9RHABcE/D8hywB7C0zs6Sxku6WtJ8SfMkfbnE\n15M0S9Ld5e+oEpek70taIGmupG0ajnVgaX+3pAMH8F4jIiKiQd3TASf3jEk6EzixZj8vA8fYvkXS\nusDNkmYBBwFX2v5meUzxccCxVAXGpLJsB/wI2E7SeqXPyVQjEzdLmmn7iZp5RERERPFG7vh3K/Ch\nOg1tL7Z9S1l/BpgPjAX2ArqfUDgd2Lus7wWc7cr1wEhJY4CPArNsLy1f/LOA3d/Ae4iIiOhYdecE\n7NIjtBawL3DnQDuUNBF4D3ADsJHtxVAVCpI2LM3GAgsbdusqsb7iPfuYAkwBmDBhwkBTjIiI6Ah1\nLxE8s8fr56hGAvYbSGfl+QO/BI60/bSkPpv2EnM/8dcG7KmUqxkmT57c64TGiIiITld3TsCmb7Qj\nSatSFQA/s31RCT8iaUwZBRgDPFriXcD4ht3HAYtKfKce8WveaG4RERGdqPacAEkjJf2NpL8tf0cN\nYF9RjSbMt316w6aZVDchovy9pCF+QLlKYHuqWxUvBi4HdpM0qvS/W4lFRETEAA1kTsBFwF3AA8AE\n4IeSPmX7yhqH2AHYH7hdUveDiE4AvglcIOkQ4EFgn7LtMmBPqksT/wAcDGB7qaRTgZtKu1Ns17pM\nMSIiIl6r7pyAHwBTbF/QHZC0D/BD4J3L29n2bHo/nw+way/tDRzex7GmAdNq5BwRERH9qHs64K1U\n5/MbXQxsPLjpRERERKvULQLO5vW/zL9Y4hERETEE9Xk6QNJ/8+rld28Cvijpq1SPDx4LbARc3/QM\nIyIioin6mxPw0x6vz2hmIhEREdFafRYBtqf3tS0iIiKGvjfy7ICIiIgYwlIEREREdKgUARERER2q\nzyJA0vUN6ye2Jp2IiIholf5GAjaXtEZZP6YVyURERETr9HeJ4CXA7yXdD6wp6dreGtnesRmJRURE\nRHP1d4ngwZI+CEwE3kf1FMCIiIgYJvp9gFB58M9sSavlvgERERHDS62nCNqeJmlnqscBj6W6dfC5\ntq9qZnIRERHRPLUuEZR0KHA+8DBwEbAY+Lmkw5qYW0RERDRRrZEA4KvAR2zf1h2QdD7V44XzTIGI\niIghqO7NgtYH7uwRuwtYb3DTiYiIiFapWwTMBk6XtBaApLWBfwJ+06zEIiIiornqFgFfAP4ceErS\nI8CTwLuBzzcrsYiIiGiuulcHLAY+JGkc8FZgke2upmYWERERTVV3YiAA5Ys/X/4RERHDQEueIihp\nmqRHJd3REDtJ0kOSbi3Lng3bjpe0QNJdkj7aEN+9xBZIOq4VuUdERAxXrXqU8FnA7r3Ev2t767Jc\nBiBpS2BfYKuyz79IGiFpBPBDYA9gS2C/0jYiIiJWwHKLAElvkrSLpNVWtBPb1wJLazbfC5hh+wXb\n9wELgG3LssD2vbZfBGaUthEREbECllsE2H4FuKR88Q62IyTNLacLRpXYWGBhQ5uuEusr/jqSpkia\nI2nOkiVLmpB2RETE0Ff3dMC1krYf5L5/BLwd2JrqNsTfKXH10tb9xF8ftKfanmx78ujRowcj14iI\niGGn7tUBDwD/IekSql/jf/rytf31FenY9iPd65LOAC4tL7uA8Q1NxwGLynpf8YgAPnf+59qdwkpr\n2qentTuFiJVO3ZGANYF/o/ryH0f1Zdy9rBBJYxpefhLovnJgJrCvpNUlbQpMAm4EbgImSdq0zE/Y\nt7SNiIiIFVD3ZkEHv5FOJJ0H7ARsIKkLOBHYSdLWVIXF/ZS7D9qeJ+kCqmcVvAwcbntZOc4RwOXA\nCGCa7XlvJK+IiIhOVvtmQZK2AP4K2Mj2EZLeAaxue+7y9rW9Xy/hM/tpfxpwWi/xy4DL6uYcERER\nfat1OkDSPsC1VLPxDyjhdYHTm5RXRERENFndOQGnAB+x/QVgWYndRvUQoYiIiBiC6hYBG1J96cOr\nVwaYPi7Ri4iIiJVf3SLgZmD/HrF9qWbtR0RExBBUd2Lgl4ArJB0CrC3pcmBzYLemZRYRERFNVfcS\nwd9Jeifwcaqb+iwELrX9bDOTi4iIiOapfYmg7T9Iug64D1iUAiAiImJoq3uJ4ARJ/011U59fAfdL\nmi1pk2YmFxEREc1Td2LgdKrJgSNtbwiMorqN7/RmJRYRERHNVfd0wHuB3Wy/BGD7WUnHAo83LbOI\niIhoqrojAdcD2/aITQZ+O7jpRERERKv0ORIg6ZSGl/cAl0n6FdWVAeOBPYGfNze9iIiIaJb+Tgf0\nfEzwReXvhsALwMXAGs1IKiIiIpqvzyLgjT4+OCIiIlZuA3mU8FrAZsA6jXHbvxnspCIiIqL5ahUB\nkg4AfgC8CDzfsMnAhCbkFREREU1WdyTgW8CnbM9qZjIRERHROnUvEXwRuKaJeURERESL1S0C/g44\nXdIGzUwmIiIiWqduEfB74BPAI5KWleUVScuamFtEREQ0Ud0i4BzgbODdwOZlmVT+LpekaZIelXRH\nQ2w9SbMk3V3+jipxSfq+pAWS5krapmGfA0v7uyUdWDP3iIiI6EXdImB94Ou277B9T+NSc/+zgN17\nxI4DrrQ9CbiyvAbYg6rAmARMAX4EVdEAnAhsR3UL4xO7C4eIiIgYuLpFwL8C+69oJ7avBZb2CO/F\nq08hnA7s3RA/25XrgZGSxgAfBWbZXmr7CWAWry8sIiIioqa6lwhuCxwh6f8DjzRusL3jCva9ke3F\n5RiLJW1Y4mOpnk/QravE+oq/jqQpVKMITJiQ2xhERET0pm4RcEZZWkG9xNxP/PVBeyowFWDy5Mm9\ntomIiOh0tYoA29OX32rAHpE0powCjAEeLfEuXvvwonHAohLfqUf8mibkFRER0RHq3jb4c31tsz1t\nBfueCRwIfLP8vaQhfoSkGVSTAJ8qhcLlwDcaJgPuBhy/gn1HRER0vLqnA3pOCtwYeDtwHbDcIkDS\neVS/4jeQ1EU1y/+bwAWSDgEeBPYpzS8D9gQWAH8ADgawvVTSqcBNpd0ptntONoyIaKqbD5vS7hRW\nau89Y2q7U4gBqHs6YOeesTI6sEXN/ffrY9OuvbQ1cHgfx5lGjaIjIiIilq/uJYK9OQs4ZJDyiIiI\niBarOyegZ7GwFvBZ4MlBzygiIiJaou6cgJd5/eV4DwGHDW46ERER0Sp1i4BNe7x+zvZjg51MRERE\ntE7diYEPNDuRiIiIaK1+iwBJV9PHXfkK237dDP+IiIhY+S1vJODcPuJjgS9RTRCMiIiIIajfIsD2\nmY2vJa1PdZe+w4DzgVOal1pEREQ0U637BEh6c7lb3wJgI2Ab21NsdzU1u4iIiGia5c0JWBM4EjiG\n6mE9H7Q9rwV5RUREhzr/u9e2O4WV2qeP2nHQjrW8OQH3ASOAbwFzgI0kbdTYwPZVg5ZNREREtMzy\nioA/Ul0d8MU+tht426BmFBERES2xvImBE1uUR0RERLTYG3mAUERERAxhKQIiIiI6VIqAiIiIDpUi\nICIiokOlCIiIiOhQKQIiIiI6VIqAiIiIDtX2IkDS/ZJul3SrpDkltp6kWZLuLn9HlbgkfV/SAklz\nJW3T3uwjIiKGrrYXAcXOtre2Pbm8Pg640vYk4MryGmAPYFJZpgA/anmmERERw8TKUgT0tBcwvaxP\nB/ZuiJ/tyvXASElj2pFgRETEULcyFAEGrpB0s6QpJbaR7cUA5e+GJT4WWNiwb1eJvYakKZLmSJqz\nZMmSJqYeERExdC3vAUKtsIPtRZI2BGZJ+l0/bdVLzK8L2FOBqQCTJ09+3faIiIhYCUYCbC8qfx8F\nLga2BR7pHuYvfx8tzbuA8Q27jwMWtS7biIiI4aOtRYCktSWt270O7AbcAcwEDizNDgQuKeszgQPK\nVQLbA091nzaIiIiIgWn36YCNgIsldefyc9u/lnQTcIGkQ4AHgX1K+8uAPYEFwB+Ag1ufckRExPDQ\n1iLA9r3Au3uJPw7s2kvcwOEtSC0iImLYa/ucgIiIiGiPFAEREREdKkVAREREh0oREBER0aFSBERE\nRHSoFAEREREdKkVAREREh0oREBER0aFSBERERHSoFAEREREdKkVAREREh0oREBER0aFSBERERHSo\nFAEREREdKkVAREREh0oREBER0aFSBERERHSoFAEREREdKkVAREREh0oREBER0aFSBERERHSoIVkE\nSNpd0l2SFkg6rt35REREDEVDrgiQNAL4IbAHsCWwn6Qt25tVRETE0DPkigBgW2CB7XttvwjMAPZq\nc04RERFDjmy3O4cBkfRXwO62Dy2v9we2s31EQ5spwJTy8h3AXS1P9I3ZAHis3UkMc/mMWyOfc/Pl\nM26+ofgZb2J79PIardKKTAaZeom9ppKxPRWY2pp0Bp+kObYntzuP4SyfcWvkc26+fMbNN5w/46F4\nOqALGN/wehywqE25REREDFlDsQi4CZgkaVNJqwH7AjPbnFNERMSQM+ROB9h+WdIRwOXACGCa7Xlt\nTmuwDdlTGUNIPuPWyOfcfPmMm2/YfsZDbmJgREREDI6heDogIiIiBkGKgIiIiA6VImAlImmapEcl\n3dHuXIYrSeMlXS1pvqR5kr7c7pyGG0lrSLpR0m3lMz653TkNV5JGSPofSZe2O5fhStL9km6XdKuk\nOe3OZ7BlTsBKRNKOwLPA2bbf1e58hiNJY4Axtm+RtC5wM7C37TvbnNqwIUnA2raflbQqMBv4su3r\n25zasCPpaGAy8GbbH293PsORpPuBybaH2s2CaslIwErE9rXA0nbnMZzZXmz7lrL+DDAfGNverIYX\nV54tL1ctS35tDDJJ44CPAT9tdy4xdKUIiI4laSLwHuCG9mYy/JRh6luBR4FZtvMZD77vAV8FXml3\nIsOcgSsk3VxuST+spAiIjiRpHeCXwJG2n253PsON7WW2t6a6o+e2knJ6axBJ+jjwqO2b251LB9jB\n9jZUT649vJy2HTZSBETHKeepfwn8zPZF7c5nOLP9JHANsHubUxludgA+Uc5XzwB2kXRue1Manmwv\nKn8fBS6mepLtsJEiIDpKmbR2JjDf9untzmc4kjRa0siyvibwYeB37c1qeLF9vO1xtidS3Tr9Ktuf\nbXNaw46ktcsEYiStDewGDKurt1IErEQknQf8FniHpC5Jh7Q7p2FoB2B/ql9Ot5Zlz3YnNcyMAa6W\nNJfqWR+zbOcSthiKNgJmS7oNuBH4le1ftzmnQZVLBCMiIjpURgIiIiI6VIqAiIiIDpUiICIiokOl\nCIiIiOhQKQIiIiI6VIqAiBjDd3npAAAEGUlEQVQSJP1Y0t8N4vHOkvT3g3W8iKEoRUDEECHpg5J+\nI+kpSUslXSfpfWXbQZJmtzvHZrL9BduntjuPiOFklXYnEBHLJ+nNwKXAF4ELgNWA/wO8MEjHX8X2\ny4NxrHYY6vlHtEtGAiKGhs0BbJ9XHs7zvO0rbM+VtAXwY+D9kp6V9CSApI9J+h9JT0taKOmk7oNJ\nmijJkg6R9CBwlaQ1JJ0r6XFJT0q6SdJGvSUj6ThJ90h6RtKdkj7ZY/thkuY3bN+mxN8j6ZYSP1/S\njO4h+d5GM0qOm5X1sxra7lTuqnmspIeBfy3xj5e7QD5ZRk3+vOFYr+kbWOON/INEDAcpAiKGht8D\nyyRNl7SHpFHdG2zPB74A/Nb2OrZHlk3PAQcAI6meO/9FSXv3OO6HgC2AjwIHAm8BxgPrl2M+30c+\n91CNRLwFOBk4V9IYAEn7ACeVvt8MfAJ4XNJqwL8B5wDrAb8APrVCn0Zl43KcTYAppdCYBny+5P8T\nYKak1ZvQd8SwkCIgYggojzv+INWzzc8Alkia2dcv9bLPNbZvt/2K7bnAeVRf+o1Osv2c7eeBl6i+\nPDcrow039/WYZdu/sL2oHPt84G5efbraocC3bN/kygLbDwDbA6sC37P9ku0LqZ4tsKJeAU60/ULJ\n/zDgJ7ZvKPlPpzpdsn0T+o4YFlIERAwRtufbPsj2OOBdwFuB7/XVXtJ2kq6WtETSU1S/7Dfo0Wxh\nw/o5wOXADEmLJH2rPHa5t2Mf0DDs/mTJp/vY46lGCnp6K/CQX/vAkgf6fsfLtcT2HxtebwIc051T\nyWt86Xew+44YFlIERAxBtn8HnEX15QvVCEFPPwdmAuNtv4Vq3oB6HqrhmC/ZPtn2lsAHgI9TDem/\nhqRNqEYjjgDWL6cf7mg49kLg7b3ksxgYWx7n3G1Cw/pzwFoN/WzcyzF6zb2h39Nsj2xY1rJ9Xo2+\nIzpSioCIIUDSOyUdI2lceT0e2A+4vjR5BBhXzn13WxdYavuPkrYFPrOcPnaW9GeSRgBPU50eWNZL\n07WpvoCXlP0O5tViBOCnwFckvVeVzUrh8FvgZeBLklaR9Je8egoB4DZgK0lbS1qDal7BQJwBfKGM\ngEjVs+A/pup58MvrO6IjpQiIGBqeAbYDbpD0HNWX/x3AMWX7VcA84GFJj5XY/wVOkfQM8HWqSwv7\nszFwIVUBMB/4L+Dcno1s3wl8h+qL9RHgz4DrGrb/AjiNaiTiGaoJeevZfhH4S+Ag4Ang08BFDfv9\nHjgF+E+qOQYDuu+B7TlU8wJ+UI6/oPTF8vqO6FR67SmyiIjWkXQW0GX7a+3OJaITZSQgIiKiQ6UI\niIiI6FA5HRAREdGhMhIQERHRoVIEREREdKgUARERER0qRUBERESHShEQERHRof4XR7Pew+iyIWkA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10db5abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=yelp['stars'].value_counts()\n",
    "y=x.sort_index()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(y.index, x.values, alpha=0.8)\n",
    "plt.title(\"Yelp Stars for business\")\n",
    "plt.ylabel('Number of businesses', fontsize=12)\n",
    "plt.xlabel('Stars acquired ', fontsize=12);\n",
    "#counting the number of reviews for each of the rating level available to the reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  My wife took me here on my birthday for breakf...       1\n",
       "1  I have no idea why some people give bad review...       1\n",
       "2  love the gyro plate. Rice is so good and I als...       1\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...       1\n",
       "4  General Manager Scott Petello is a good egg!!!...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp[\"labels\"]= yelp[\"stars\"].apply(lambda x: 1 if x >= 3  else 0)\n",
    "yelp=yelp.drop(\"stars\",axis=1)\n",
    "\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS=1000\n",
    "MAX_SEQUENCE_LENGTH=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAX_NUM_WORDS value means the number of unique rows to be used in the embedding vector, which coreesponds to the number of unique words to be used. The MAX_SEQUENCE_LENGTH value means the maximum length of a review to use, means the maximum number of words to be taken from a certain review sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to preprocess the text data in integerized word vectors using the Glove word vectors so that we can give that input to our LSTM neural network. The first step in preprocessing will be tokenization, which will seperate each unique words from the sentence, and we will use pad_sequences to pad the sentences to the maximum sequence length MAX_SEQUENCE_LENGTH defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = yelp[\"text\"].values\n",
    "labels = yelp[\"labels\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts) # fit the tokenizer on the review text column\n",
    "sequences = tokenizer.texts_to_sequences(texts) #text to sequence transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30816 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10000, 100)\n",
      "Shape of label tensor: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.2 # we take 20% of the data as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices) # randomly shuffle indices to increase diversity in the training set.\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spliting into training and testing set.\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GLOVE_DIR='../input/glove-global-vectors-for-word-representation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B.50d.txt'), encoding = \"utf8\")\n",
    "\n",
    "#if you are on a windows machine please use the line below and comment out the above line as we need to provide the path reference in windows.\n",
    "#f = open(os.path.join(GLOVE_DIR, 'glove.6B.50d.txt'), encoding = \"utf8\")\n",
    "# download the glove zip from - https://nlp.stanford.edu/projects/glove/\n",
    "#and put it in the directory of this notebook.\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "# the above for loop iterates along every word and its corresponding vector given in the Glove text file, \n",
    "#and creates a dictionary with the key as the word and the value as the corresponding  integerized word vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have specified the EMBEDDING_DIM value as 50, and we have found 400000 word vectors, the dimensions of our embedding matrix will be 400000 x 50.\n",
    "\n",
    "Now the for loop in the next block of code will take each of the word from the unique words collections of word_index which we defined before from out review texts, and search for the corresponding word vector from the embeddings index dictionary.\n",
    "Now we will put each of the retrieved embedding vector in the embedding matrix, which will be passed as an input to out embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "\n",
    "#keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as above we have set the sequence length as 100 for each sequence and the output dimensions as 50, we will get a sequence vector of dimension 100 x 50 for each of the 100 words in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, GlobalMaxPool1D,Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "x = embedded_sequences = embedding_layer(inp)\n",
    "x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "# as we have set the output dimensions of the embedding layer as 50, we set the input neurons of the first LSTM layer succeding that as 50.\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(2, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of \n",
    "#parameters and amount of computation in the network, and hence to also control overfitting. \n",
    "#It is common to periodically insert a pooling layer between successive convolutional layers in a CNN architecture.\n",
    "#The pooling operation provides another form of translation invariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Binary Crossentropy because we are dealing with binary classification problem here, we chose the activation functions as rectified Linear and Sigmoid for the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/2\n",
      "8000/8000 [==============================] - 16s 2ms/step - loss: 0.4538 - acc: 0.8287 - val_loss: 0.4463 - val_acc: 0.8125\n",
      "Epoch 2/2\n",
      "8000/8000 [==============================] - 14s 2ms/step - loss: 0.3915 - acc: 0.8380 - val_loss: 0.3836 - val_acc: 0.8195\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=2, batch_size=128);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8195\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_val, y_val,\n",
    "                            batch_size=32,\n",
    "                            verbose=2)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Some code snippets have been referenced from:\n",
    "https://github.com/adeshpande3/LSTM-Sentiment-Analysis/blob/master/Oriole%20LSTM.ipynb\n",
    "by Adit Deshpande is licensed under the MIT License https://opensource.org/licenses/MIT.\n",
    "\n",
    "\n",
    "https://www.kaggle.com/poonaml/bidirectional-lstm-spacy-on-yelp-reviews/notebook\n",
    "open sourced public blog on kaggle.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
